{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fashion-MNIST FF-Neural Network torch intro\n",
    "The `torch.nn` namespace provides all the building blocks you need to build your own neural network. \n",
    "\n",
    "Every module in PyTorch subclasses the `nn.Module`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using mps device\n"
     ]
    }
   ],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a FF-Neural Network class\n",
    "We define our neural network by subclassing nn.Module, and initialize the neural network layers in `__init__`. \n",
    "\n",
    "Every `nn.Module `subclass implements the operations on input data in the forward method.\n",
    "\n",
    "Below, before we call the forward of the feed-forward method we **flatten** the input tensor. In many cases, such as in cases of image data, the data is represented as a multi-dimensional array of tensor, for example [batch_size, 28, 28] for a batch of images with 28x28 pixels. To make such data compatible with a standard fully connected we have to flatten it so that each pixel correspond to a neuron in the network at the input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x) # call class flatten method\n",
    "        logits = self.linear_relu_stack(x) # call the forward pass for the neural network\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create an instance of `NeuralNetwork`, and move it to the `device`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the model, we pass it the input data. This executes the model’s `forward`, along with some background operations. Do not call `model.forward()` directly!\n",
    "\n",
    "Calling the model on the input returns a 2-dimensional tensor with dim=0 corresponding to each output of 10 raw predicted values for each class, and dim=1 corresponding to the individual values of each output. We get the prediction probabilities by passing it through an instance of the `nn.Softmax` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: tensor([6], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(1, 28, 28, device=device) # batch of single 28x28 'pixel' image as input data\n",
    "logits = model(X) # yields the final layer neuron outputs\n",
    "pred_probab = nn.Softmax(dim=1)(logits) # creates prob of these outputs corresponding to different classes by using the softmax function\n",
    "y_pred = pred_probab.argmax(1) # Takes the argment with the largest prob as the predicted class \n",
    "print(f\"Predicted class: {y_pred}\") # predicts class from the total of 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this network, w and b are parameters, which we need to optimize. Thus, we need to be able to compute the gradients of loss function with respect to those variables. In order to do that, we set the requires_grad property of those tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root = \"data\", # path where data will be stored\n",
    "    train = True, # \n",
    "    download = True,\n",
    "    transform=ToTensor() # convert ndarray to torch.tensor\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n",
      "Dataset FashionMNIST\n",
      "    Number of datapoints: 10000\n",
      "    Root location: data\n",
      "    Split: Test\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(training_data)\n",
    "print(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset with a specific batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=64)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Hyperparameters\n",
    "\n",
    "Define the following hyperparameters for training:\n",
    "- **Number of Epochs** - the number times to iterate over the dataset\n",
    "- **Batch Size** - the number of data samples propagated through the network before the parameters are updated\n",
    "- **Learning Rate** - how much to update models parameters at each batch/epoch. Smaller values yield slow learning speed, while large values may result in unpredictable behavior during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "bs = 64\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimization loop\n",
    "\n",
    "Once we set our hyperparameters, we can then train and optimize our model with an optimization loop. Each iteration of the optimization loop is called an epoch.\n",
    "\n",
    "Each epoch consists of two main parts:\n",
    "- The Train Loop - iterate over the training dataset and try to converge to optimal parameters.\n",
    "- The Validation/Test Loop - iterate over the test dataset to check if model performance is improving."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss function\n",
    " Loss function measures the degree of dissimilarity of obtained result to the target value, and it is the loss function that we want to minimize during training. To calculate the loss we make a prediction using the inputs of our given data sample and compare it against the true data label value.\n",
    "\n",
    " Common loss functions include nn.MSELoss (Mean Square Error) for regression tasks\n",
    "\n",
    "nn.NLLoss (Negative Log Likelihood) for classification\n",
    "\n",
    "nn.CrossEntropyLoss combines nn.LogSoftmax and nn.NLLLoss to yield a probabiliy in our prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the loss function\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizer\n",
    "\n",
    "Optimization is the process of adjusting model parameters to reduce model error in each training step. \n",
    "\n",
    "Optimization algorithms define how this process is performed (in this example we use Stochastic Gradient Descent). All optimization logic is encapsulated in the optimizer object.\n",
    "\n",
    "Initalize the optimizer by passing the model's parameters that need to be trained, and passing any optimizer relevant hyperparameters such as learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr= lr) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside the training loop, optimization happens in three steps:\n",
    "\n",
    "- Call optimizer.zero_grad() to reset the gradients of model parameters. Gradients by default add up; to prevent double-counting, we explicitly zero them at each iteration.\n",
    "- Backpropagate the prediction loss with a call to loss.backward(). PyTorch deposits the gradients of the loss w.r.t. each parameter.\n",
    "- Once we have our gradients, we call optimizer.step() to adjust the parameters by the gradients collected in the backward pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Test Loop\n",
    "We define train_loop that loops over our optimization code, and test_loop that evaluates the model’s performance against our test data.\n",
    "\n",
    "The training loop consists of:\n",
    "1) Setting the model to train\n",
    "2) Iterate over each batch, get the features and labels\n",
    "3) For each batch, obtain the model predictions\n",
    "4) Compute the loss (deviation from model pred to true label)\n",
    "5) Start backpropagation by computing the gradients wrt to each parameter of each node to obtain the change to derivative of the loss function\n",
    "6) Adjust the node parameters (weight and biases) by the gradients\n",
    "7) Reset th gradients of the model to prepare for the next batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    # Set the model to training mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.train()\n",
    "    \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        \n",
    "        # Move the data to the device (GPU or MPS)\n",
    "        X = X.to(device)\n",
    "        y =y.to(device)\n",
    "        \n",
    "        # Get prediction and compute loss\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        \n",
    "        # Back-prop\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * bs + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "def test_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0 # tally the number of correct predictions\n",
    "    \n",
    "   # Set the model to evaluation mode - important for batch normalization and dropout layers\n",
    "    # Unnecessary in this situation but added for best practices\n",
    "    model.eval()\n",
    "\n",
    "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
    "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            \n",
    "            # Move the data to the device (GPU or MPS)\n",
    "            X = X.to(device)\n",
    "            y =y.to(device)\n",
    "            \n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    \n",
    "    # TODO: Explain the two steps below\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and Test loop execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 1.891896  [   64/60000]\n",
      "loss: 1.867726  [ 6464/60000]\n",
      "loss: 1.732750  [12864/60000]\n",
      "loss: 1.770723  [19264/60000]\n",
      "loss: 1.671376  [25664/60000]\n",
      "loss: 1.620758  [32064/60000]\n",
      "loss: 1.636911  [38464/60000]\n",
      "loss: 1.540162  [44864/60000]\n",
      "loss: 1.565440  [51264/60000]\n",
      "loss: 1.464948  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.4%, Avg loss: 1.484152 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 1.553514  [   64/60000]\n",
      "loss: 1.529315  [ 6464/60000]\n",
      "loss: 1.366726  [12864/60000]\n",
      "loss: 1.444998  [19264/60000]\n",
      "loss: 1.329574  [25664/60000]\n",
      "loss: 1.320425  [32064/60000]\n",
      "loss: 1.337247  [38464/60000]\n",
      "loss: 1.260398  [44864/60000]\n",
      "loss: 1.301708  [51264/60000]\n",
      "loss: 1.212306  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.8%, Avg loss: 1.232651 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.306572  [   64/60000]\n",
      "loss: 1.298569  [ 6464/60000]\n",
      "loss: 1.123892  [12864/60000]\n",
      "loss: 1.238328  [19264/60000]\n",
      "loss: 1.112033  [25664/60000]\n",
      "loss: 1.128571  [32064/60000]\n",
      "loss: 1.155038  [38464/60000]\n",
      "loss: 1.088073  [44864/60000]\n",
      "loss: 1.136229  [51264/60000]\n",
      "loss: 1.063919  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.1%, Avg loss: 1.076266 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.143139  [   64/60000]\n",
      "loss: 1.153264  [ 6464/60000]\n",
      "loss: 0.964232  [12864/60000]\n",
      "loss: 1.106403  [19264/60000]\n",
      "loss: 0.977818  [25664/60000]\n",
      "loss: 0.998350  [32064/60000]\n",
      "loss: 1.041295  [38464/60000]\n",
      "loss: 0.976978  [44864/60000]\n",
      "loss: 1.025923  [51264/60000]\n",
      "loss: 0.970122  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 66.1%, Avg loss: 0.974079 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.028489  [   64/60000]\n",
      "loss: 1.058402  [ 6464/60000]\n",
      "loss: 0.853962  [12864/60000]\n",
      "loss: 1.017119  [19264/60000]\n",
      "loss: 0.892854  [25664/60000]\n",
      "loss: 0.906093  [32064/60000]\n",
      "loss: 0.966530  [38464/60000]\n",
      "loss: 0.904123  [44864/60000]\n",
      "loss: 0.948710  [51264/60000]\n",
      "loss: 0.907370  [57664/60000]\n",
      "Test Error: \n",
      " Accuracy: 67.2%, Avg loss: 0.903983 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn, optimizer)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check single predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_indices = [1] # select your indices here as a list\n",
    "subset = torch.utils.data.Subset(train_dataloader.dataset, subset_indices)\n",
    "testloader_subset = torch.utils.data.DataLoader(subset, batch_size=1, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual class: T-shirt/top \n",
      "Predicted class: T-shirt/top\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "\n",
    "# Function to map integer labels to corresponding class names\n",
    "def get_class_name(label):\n",
    "    classes = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
    "    return classes[label]\n",
    "\n",
    "for x, y in testloader_subset:\n",
    "    model.eval()\n",
    "    model_pred = model(x.to(device))\n",
    "    model_pred = model_pred.detach().cpu().numpy().argmax(1)[0]\n",
    "    x = x.squeeze().detach().numpy()\n",
    "    plt.imshow(x, cmap='gray')\n",
    "    plt.show()\n",
    "    print(f\"Actual class: {get_class_name(y.detach().cpu().numpy()[0])} \\nPredicted class: {get_class_name(model_pred)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
